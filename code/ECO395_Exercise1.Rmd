---
title: "ECO395M: Exercise 1"
author: "Kashaf Oneeb"
date: "2/10/2022"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Problem 1 Data visualization: flights at ABIA
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#load packages
library(tidyverse)
library(ggplot2)
library(dplyr)
library(here)

here::i_am("code/ECO395_Exercise1.Rmd")

#read in data
ABIA <- read.csv(here("data/ABIA.csv"))
```
## Check the number of destinations
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
length(unique(ABIA$Dest))
```
## Identify the most popular destinations as destinations with more than 2000 flights
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
table(ABIA$Dest)
```
## Chose the following Destinations
#ATL=2252 AUS=49637 DAL=5573 DEN= 2673 
#DFW= 5506 HOU=2319 IAH=3691 ORD=2514 PHX=2783

## Create new data frame by Destination and Month for the most popular destinations
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#group new data frame by Destination and Month
group_cols1 <- c("Month", "Dest")
ABIA_Month_Dest <- ABIA %>%
  group_by(across(all_of(group_cols1))) %>%
  filter(Dest %in% c("ATL", "AUS", "DAL", "DEN", "DFW", "HOU", "IAH", "ORD", "PHX")) %>%
  summarize(count = n(), 
            mean_ArrDelay = mean(ArrDelay, na.rm =TRUE))
ABIA_Month_Dest
```
```{r p_arr_delay, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}


#make a bar plot of mean_ArrDelay and Month mean_ArrDelay faceted by Destination
p_arr_delay <- ggplot(ABIA_Month_Dest) +
  geom_col(aes(x=factor(Month), y=mean_ArrDelay)) +
  facet_wrap(~Dest) +
  labs(title = "Mean Arrival Delay per Month by Popular Destinations",
      x = "Month",
      y = "Mean Arrival Delay",
      caption = "Figure 1: A bar plot of Mean Arrival Delay for all Months faceted by destination airports. ")
plot(p_arr_delay)
```
## What is the best time of year to fly to minimize delays, and does this change by destination?

The plots reflect that September is probably the best month to fly in the year as it has the lowest average arrival delays compared to other months. This is generally true for all of the destinations except Chicago O'Hare Int'l Airport (ORD) and Dallas Love Field Airport (DAL). However, even for these exceptions, the average delays are relatively lower in September. Furthermore, Denver Int'l Airport (DEN) and George Bush Intercontinental Airport (IAH) even gain time in September since their average arrival delays are negative.
On a more general level, the best range of months to fly to minimze arrival delays is September to November, as the the average arrival delays are lower for this range compared to other months. This too is generally true across destinations, with Hartsfield-Jackson Atlanta Int'l Airport(ATL) deviating from the general pattern slighty. ATL does not necessarily have a consecutive range of months with lower delays, instead, it has specific months, which include January, May, and September.

# Problem 2: Wrangling the Billboard Top 100
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#load packages
library(tidyverse)
library(ggplot2)
library(dplyr)

#read in data
billboard <- read.csv(here("data/billboard.csv"))
```
## Part A

### Create a new data frame for the top 10 most poplar songs
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}

#identify the top 10 most popular songs
billboard_top10 <- billboard %>%
  group_by(performer, song) %>%
  summarize(count = n()) %>%
  arrange(desc(count)) %>%
  head(10)
```
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}

#make a table of top 10 most popular songs
knitr::kable(
  billboard_top10,
  caption = "The top 10 most popular songs since 1958 arranged by the total number of weeks that a song spent on the Billboard Top 100",
             col.names = c("Performer", "Song","Total # of weeks"))
```
## PART B
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#filter out 1958 and 2021 and find the number of times a song appears on the Top 100 in a given year
billboard_count <- billboard %>%
  filter(!year %in% c("1958", "2021")) %>%
  group_by(year, song_id) %>%
  summarize(count = n())


  
#count the number of unique songs that appeared on the Top 100 in a given year
billboard_unique <- billboard_count %>%
  group_by(year) %>%
  summarize(count = n())
```
```{r p_bill_unique, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#make a line graph of the number unique songs against years
p_bill_unique <- ggplot(billboard_unique) +
  geom_line(aes(x = year, y = count)) +

  labs(title = "Measure of musical diversity over the years",
       y = "Number of unique songs in Billboard Top 100",
       x = "Year",
       caption = "Figure 2: A line graph of the number of unique songs that appeared in the Billboard Top 100 in a given year from 1959 to 2020.")
plot(p_bill_unique)
```
The line graph shows that the musical diversity in the Billboard Top 100 rose somewhat steadily from 1959 to mid 1960's, reaching above 800 unique songs at the end of the period. From the mid 1960's to early 2000's, the musical diversity decreased sharply and fairly consistently, reaching a low of approximately 390 unique songs in 2001, which is the lowest value it reached between 1959 and 2020. From the early 2000's till 2020, the musical diversity was quite volatile, it rose sharply and steadily till 2012, reaching over 600 unique songs. This steady rise was followed by a sharp decline which continued till 2014, dropping the number of unique songs to approximately 475 songs in 2014. 2014 onwards, the musical diversity rose dramatically and fairly consistently, rising to 800 unique songs in 2020. In general, musical diversity seems to vary with time with volatility; the absence of flat regions in the line graph reflects the instability of musical diversity over the years.

## Part C
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#Identify ten-week hits: songs that appeared on the Billboard Top 100 for at least ten weeks
billboard_10hits <- billboard %>%
  group_by(song, performer) %>%
  summarize(count = n()) %>%
  filter(count >= 10)

#Identify artists who have had at least 30 songs that were ten-week hits

billboard_30 <- billboard_10hits %>%
  group_by(performer) %>%
  summarize(count = n()) %>%
  filter(count >= 30)

```
```{r p_bill_30, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#Make a bar plot of the 19 artists with at least 30 songs that were ten-week hits
p_bill_30 <- ggplot(billboard_30) +
  geom_col(aes(fct_reorder(performer, 
                           count),
               count)) +
  coord_flip() +
  labs(title = "19 artists with at least 30 songs that were ten-week hits",
       y = "Number of songs that were ten-week hits",
       x = "Artist",
       caption = "Figure 3: A bar plot of 19 artists with at least 30 songs that were ten-week hits. ")
plot(p_bill_30)
```

The bar plot shows the 19 artists who had at least 30 ten-week hits which are songs that appeared on the Billboard Top 100 for at least ten weeks.

# Problem 3: Wrangling the Olympics
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}


#load tidyverse
library(tidyverse)
library(ggplot2)
library(dplyr)

#read in data
olympics <- read.csv(here("data/olympics_top20.csv"))
```
## PART A

### The 95th percentile of heights for female competitors across all Athletics events
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}

#95th percentile of heights for female competitors across all Athletics events
athletics <- olympics %>%
  filter(sport == "Athletics" & sex == "F") %>%
  group_by(event) %>%
  summarize(percentile_95 = quantile(height, .95, na.rm =TRUE))
athletics
```
## PART B

### The single women's event with the greatest variability in competitor's heights across the entire history of the Olympics
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#Identify a single women's event with the greatest variability in competitor's heights across the entire history of the Olympics, 
height_var <- olympics %>%
  filter(sex == "F") %>%
  group_by(event) %>%
  summarize(height_sd = sd(height, na.rm =TRUE)) %>%
  with(., event[which.max(height_sd)])
height_var
```
## PART C

## The average age of Olympic swimmers over time
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
swimmer_age <- olympics %>%
  filter(sport == "Swimming") %>%
  group_by(year, sex) %>%
  summarize(mean_age = mean(age, na.rm = TRUE))
swimmer_age
```
```{r p_swimmer_age, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#plot a line graph of average age over time for males and females
p_swimmer_age <- ggplot(swimmer_age) +
  geom_line(aes(x=year, y=mean_age, color = sex)) +
  labs(title = "Average age of Olympic swimmers over time",
       y = "Average Age",
       x = "Year",
       caption = "Figure 4: The average age of Olympic swimmers over the years differentiated by Sex")
plot(p_swimmer_age)
```
From 1900 to early 1920's, the average age of male Olympics swimmers rose fairly steadily and sharply from 18 years old to 32 years old, approximately. For the same period, there is missing data for female Olympics swimmers so no comparison can be made of average age over time by sex. From early  to early 1930's, the average age of males fell sharply and consistently to 19 years old, approximately. The average age for females also fell during this time period but much less dramatically. From the early 1930's to the early 1980's, the average age for both males and females remained relatively constant hovering around 20-years-old for males and 17-years-old for females, approximately. After the early 1980's, both genders saw a steady but gradual increase in the average age, leading to an average age of 24-years-old for males and 22-years-old for females. Generally, the average age experienced an upward trend for both the genders since the early 1980's. Although, the average age for females has been lower than that of the males, they seem to be converging in the later years. 

# Problem 4: K-nearest neighbors
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
# for creating train/test splits
library(tidyverse)
library(ggplot2)
library(rsample)  
library(caret)
library(modelr)
library(parallel)
library(foreach)

#read in data
sclass <- read.csv(here("data/sclass.csv"))
sclass[!complete.cases(sclass),]


#filter to create two separate data frames for scclass 350 and 65 AMG
sclass_350 <- sclass %>%
  filter(trim == "350")
sclass_65 <- sclass %>%
  filter(trim == "65 AMG")

#for each of these two trim levels:
#split the data into a training and a testing set.

#make a train-test split for sclass 350
sclass_350_split <-  initial_split(sclass_350, prop=0.8)
sclass_350_train <- training(sclass_350_split)
sclass_350_test  <- testing(sclass_350_split)

#make a train-test split for sclass 65 AMG
sclass_65_split <-  initial_split(sclass_65, prop=0.8)
sclass_65_train <- training(sclass_65_split)
sclass_65_test  <- testing(sclass_65_split)


#run K-nearest-neighbors for K = 2, 10, 15, 20, 60, 80, and 100 for each trim
#for each value of K, fit the model to the training set and make predictions on the test set for each trim
#calculate the out-of-sample root mean-squared error (RMSE) for each value of K for each trim

#for sclass 350

#KNN with K = 2 and RMSE
sclass_350_knn2 <- knnreg(price ~ mileage, data=sclass_350_train, k=2)
rmse_350_knn2 <- rmse(sclass_350_knn2, sclass_350_test)

#fit the model to training set and make predictions on test set
sclass_350_test <- sclass_350_test %>%
  mutate(price_pred_knn2 = predict(sclass_350_knn2, sclass_350_test))

#KNN with K = 10 and RMSE
sclass_350_knn10 <- knnreg(price ~ mileage, data=sclass_350_train, k=10)
rmse_350_knn10 <- rmse(sclass_350_knn10, sclass_350_test)

#fit the model to training set and make predictions on test set
sclass_350_test <- sclass_350_test %>%
  mutate(price_pred_knn10 = predict(sclass_350_knn10, sclass_350_test))

#KNN with K = 15 and RMSE
sclass_350_knn15 <- knnreg(price ~ mileage, data=sclass_350_train, k=15)
rmse_350_knn15 <- rmse(sclass_350_knn15, sclass_350_test)

#fit the model to training set and make predictions on test set
sclass_350_test <- sclass_350_test %>%
  mutate(price_pred_knn15 = predict(sclass_350_knn15, sclass_350_test))

#KNN with K = 20 and RMSE
sclass_350_knn20 <- knnreg(price ~ mileage, data=sclass_350_train, k=20)
rmse_350_knn20 <- rmse(sclass_350_knn20, sclass_350_test)

#fit the model to training set and make predictions on test set
sclass_350_test <- sclass_350_test %>%
  mutate(price_pred_knn20 = predict(sclass_350_knn20, sclass_350_test))

#KNN with K = 40 and RMSE
sclass_350_knn40 <- knnreg(price ~ mileage, data=sclass_350_train, k=40)
rmse_350_knn40 <- rmse(sclass_350_knn40, sclass_350_test)

#fit the model to training set and make predictions on test set
sclass_350_test <- sclass_350_test %>%
  mutate(price_pred_knn40 = predict(sclass_350_knn40, sclass_350_test))

#KNN with K = 60 and RMSE
sclass_350_knn60 <- knnreg(price ~ mileage, data=sclass_350_train, k=60)
rmse_350_knn60 <- rmse(sclass_350_knn60, sclass_350_test)

#fit the model to training set and make predictions on test set
sclass_350_test <- sclass_350_test %>%
  mutate(price_pred_knn60 = predict(sclass_350_knn60, sclass_350_test))

#KNN with K = 80 and RMSE
sclass_350_knn80 <- knnreg(price ~ mileage, data=sclass_350_train, k=80)
rmse_350_knn80 <- rmse(sclass_350_knn80, sclass_350_test)

#fit the model to training set and make predictions on test set
sclass_350_test <- sclass_350_test %>%
  mutate(price_pred_knn80 = predict(sclass_350_knn80, sclass_350_test))

#KNN with K = 100 and RMSE
sclass_350_knn100 <- knnreg(price ~ mileage, data=sclass_350_train, k=100)
rmse_350_knn100 <- rmse(sclass_350_knn100, sclass_350_test)

#fit the model to training set and make predictions on test set
sclass_350_test <- sclass_350_test %>%
  mutate(price_pred_knn100 = predict(sclass_350_knn100, sclass_350_test))

#for sclass 65 AMG

#KNN with K = 2 and RMSE 
sclass_65_knn2 <- knnreg(price ~ mileage, data=sclass_65_train, k=2)
rmse_65_knn2 <- rmse(sclass_65_knn2, sclass_65_test)

#fit the model to training set and make predictions on test set
sclass_65_test <- sclass_65_test %>%
  mutate(price_pred_knn2 = predict(sclass_65_knn2, sclass_65_test))

#KNN with K = 10and RMSE
sclass_65_knn10 <- knnreg(price ~ mileage, data=sclass_65_train, k=10)
rmse_65_knn10 <- rmse(sclass_65_knn10, sclass_65_test)

#fit the model to training set and make predictions on test set
sclass_65_test <- sclass_65_test %>%
  mutate(price_pred_knn10 = predict(sclass_65_knn10, sclass_65_test))

#KNN with K = 15 and RMSE
sclass_65_knn15 <- knnreg(price ~ mileage, data=sclass_65_train, k=15)
rmse_65_knn15 <- rmse(sclass_65_knn15, sclass_65_test)

#fit the model to training set and make predictions on test set
sclass_65_test <- sclass_65_test %>%
  mutate(price_pred_knn15 = predict(sclass_65_knn15, sclass_65_test))

#KNN with K = 20 and RMSE
sclass_65_knn20 <- knnreg(price ~ mileage, data=sclass_65_train, k=20)
rmse_65_knn20 <- rmse(sclass_65_knn20, sclass_65_test)

#fit the model to training set and make predictions on test set
sclass_65_test <- sclass_65_test %>%
  mutate(price_pred_knn20 = predict(sclass_65_knn20, sclass_65_test))

#KNN with K = 40 and RMSE
sclass_65_knn40 <- knnreg(price ~ mileage, data=sclass_65_train, k=40)
rmse_65_knn40 <- rmse(sclass_65_knn40, sclass_65_test)
#fit the model to training set and make predictions on test set
sclass_65_test <- sclass_65_test %>%
  mutate(price_pred_knn40 = predict(sclass_65_knn40, sclass_65_test))

#KNN with K = 60 and RMSE
sclass_65_knn60 <- knnreg(price ~ mileage, data=sclass_65_train, k=60)
rmse_65_knn60 <- rmse(sclass_65_knn60, sclass_65_test)

#fit the model to training set and make predictions on test set
sclass_65_test <- sclass_65_test %>%
  mutate(price_pred_knn60 = predict(sclass_65_knn60, sclass_65_test))

#KNN with K = 80 and RMSE
sclass_65_knn80 <- knnreg(price ~ mileage, data=sclass_65_train, k=80)
rmse_65_knn80 <- rmse(sclass_65_knn80, sclass_65_test)

#fit the model to training set and make predictions on test set
sclass_65_test <- sclass_65_test %>%
  mutate(price_pred_knn80 = predict(sclass_65_knn80, sclass_65_test))

#KNN with K = 100 and RMSE
sclass_65_knn100 <- knnreg(price ~ mileage, data=sclass_65_train, k=100)
rmse_65_knn100 <- rmse(sclass_65_knn100, sclass_65_test)

#fit the model to training set and make predictions on test set
sclass_65_test <- sclass_65_test %>%
  mutate(price_pred_knn100 = predict(sclass_65_knn100, sclass_65_test))
```
#Make a plot of RMSE versus K to find the optimal value of K for each trim
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#for each trim, make a plot of RMSE versus K

#create new data frame for K and RMSE for sclass 360
RMSE_K_350 <- data.frame(K = c(2,10,15,20,40,60,80,100),
                         RMSE = c(rmse_350_knn2, rmse_350_knn10, rmse_350_knn15, rmse_350_knn20, rmse_350_knn40, rmse_350_knn60, rmse_350_knn80, rmse_350_knn100))

#plot RMSE versus K
ggplot(RMSE_K_350) +
  geom_point(aes(x=factor(K),y=RMSE)) +
  labs(title = "Sclass 350: Out-of-sample RMSE for different values of K",
       x = "K",
       y = "Out-of-sample RMSE",
       caption = "Figure 5: The optimal value of K=40 for S Class 350.")
```

#Optimal value of K=40 for S Class 350
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
               
#create new data frame for K and RMSE for sclass 65 AMG
RMSE_K_65 <- data.frame(K = c(2,10,15,20,40,60,80,100),
                         RMSE = c(rmse_65_knn2, rmse_65_knn10, rmse_65_knn15, rmse_65_knn20, rmse_65_knn40, rmse_65_knn60, rmse_65_knn80, rmse_65_knn100))

#plot RMSE versus K
ggplot(RMSE_K_65) +
  geom_point(aes(x=factor(K),y=RMSE)) +
  labs(title = "Sclass 65 AMG: Out-of-sample RMSE for different values of K",
       x = "K",
       y = "Out-of-sample RMSE",
       caption = "Figure 6: The optimal value of K=20 for S Class 65 AMG.")
```

## Optimal value of K=20 for S Class 65 AMG

### Plots of fitted model for optimal values of K for each trim
```{r echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}

#plot of the fitted model for sclass 350
p_350 <- ggplot(data = sclass_350_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2) + 
  ylim(6000, 110000) +
  labs(caption= "Figure 7: The fitted model for S Class 350 when K=40")

#add the predictions for sclass 350
p_350 + geom_line(aes(x = mileage, y = price_pred_knn40), color='red', size=1.5)


#plot of the fitted model for sclass 65 AMG
p_65 <- ggplot(data = sclass_65_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2) + 
  ylim(18000, 260000) +
  labs(caption= "Figure 8: The fitted model for S Class 65 AMG when K=20")

#add the predictions for sclass 65 AMG
p_65 + geom_line(aes(x = mileage, y = price_pred_knn20), color='red', size=1.5)

```

### Which trim yields a larger optimal value of K? 

The optimal value of K for S Class 350 is 40, whereas, the optimal value of K for S Class 65 AMG is 20.So, S Class 350 yields a larger optimal value of K. This can be attributed to the size of the two data frames, sclass_350 has 416 observations, whereas sclass_65 has 292 observations. Therfore, more data points can be averaged for S Class 350 as compared to S Class 65 AMG, hence K is larger for S Class 350.